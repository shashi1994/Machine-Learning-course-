{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zNLX1wgobzLd",
        "HQGi27JzCBeD",
        "oT1JxmBJNX70",
        "K-kusjfWPu74",
        "1mHiTYvXQQRJ",
        "uBmIjq1Ddvk6",
        "gezqTSQohvHi",
        "c5B6KY1aIXaq",
        "y-H8cK3n0J1V",
        "Ej5PrnVgLgS6",
        "ZKwqz15Fe_iZ",
        "1ylJTE2uKVqq",
        "AZpE9J7MgKbO",
        "jZ4GI-pHYqcM",
        "nrS30KZSKpSU",
        "HQwLpQtZSYVP",
        "XXDL3z0NSnYE",
        "hOw4zyssK3Hm"
      ],
      "private_outputs": true,
      "toc_visible": true,
      "authorship_tag": "ABX9TyMFKIo9BypxmdUXp5BNXSaL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashi1994/Machine-Learning-course-/blob/main/machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Supervised Learning"
      ],
      "metadata": {
        "id": "fOkxvlaF45GK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Boston datasets #"
      ],
      "metadata": {
        "id": "zNLX1wgobzLd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZJ8lgi_bXPv"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "data=datasets.load_boston()\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets \n",
        "boston=datasets.load_boston()\n",
        "# x = data\n",
        "# Y= targets \n",
        "x=boston.data\n",
        "y=boston.target\n",
        "x.shape"
      ],
      "metadata": {
        "id": "jWhwsRTXbcis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.DataFrame(x)\n",
        "print(boston.feature_names)\n",
        "df.columns=boston.feature_names\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "WdP0iNxfbclX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boston.DESCR"
      ],
      "metadata": {
        "id": "ShMDfchQbcoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UPnVuNpZbcq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* how to data tain and test "
      ],
      "metadata": {
        "id": "m0OrdeZF5N6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection\n",
        "# model_selection.train_test_split(x,y)\n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(x,y)  # x = data, x=boston.data, y=target , y=boston.target\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "QeCWCly15NAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "algl=LinearRegression()\n",
        "algl.fit(x_train, y_train)\n",
        "LinearRegression(copy_X=True,fit_intercept=True,n_jobs=1,normalize=False)\n",
        "y_pred=algl.predict(x_test)"
      ],
      "metadata": {
        "id": "1h-_ep-3bctN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(y_test,y_pred)\n",
        "plt.axis([0,40,0,40])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Qm7cv7eQbcvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(y_pred,y_test)\n",
        "plt.axis([0,40,0,40])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GnGhNISbbcyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FfTR6Nwpbc0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l9tpQFC8bc3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mZ--tPTTbc58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oxJUmz2Xbc8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ckWkhiedbc-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zbi_gAEobdBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression "
      ],
      "metadata": {
        "id": "HQGi27JzCBeD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AuS5nh_xB_hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "8Z0TokFWCiP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.loadtxt(\"data.csv\", delimiter=\",\")"
      ],
      "metadata": {
        "id": "8ud6vqZBCiTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = data[:, 0]\n",
        "y = data[:, 1]"
      ],
      "metadata": {
        "id": "6ILQh87NCiW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "kRhcLRNKCiZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection\n",
        "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(x, y, test_size=0.3)\n",
        "X_train.shape"
      ],
      "metadata": {
        "id": "f0k-v64uCI1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(x_train, y_train):\n",
        "    num = (x_train*y_train).mean() - x_train.mean() * y_train.mean()\n",
        "    den = (x_train**2).mean() - x_train.mean()**2\n",
        "    m = num/den\n",
        "    c = y_train.mean() - m * x_train.mean()\n",
        "    return m, c\n",
        "    "
      ],
      "metadata": {
        "id": "Qxxq8AgSCI4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, m, c):\n",
        "    return m * x + c\n",
        "\n",
        "def score(y_truth, y_pred):\n",
        "    u = ((y_truth - y_pred)**2).sum()\n",
        "    v = ((y_truth - y_truth.mean())**2).sum()\n",
        "    return 1 - u/v\n",
        "\n",
        "def cost (x, y, m , c):\n",
        "    return ((y - m * x - c)**2).mean()"
      ],
      "metadata": {
        "id": "RhsP1nVnCI7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m, c = fit(X_train, Y_train)\n",
        "# test data\n",
        "y_test_pred = predict(X_test, m, c)\n",
        "print(\"Test Score: \",score(Y_test, y_test_pred))\n",
        "\n",
        "#train data\n",
        "y_train_pred = predict(X_train, m, c)\n",
        "print(\"Train Score: \", score(Y_train, y_train_pred))\n",
        "print(\"M, C \", m , c)\n",
        "print(\"Cost on training data \", cost(X_train,Y_train, m, c ))"
      ],
      "metadata": {
        "id": "FcDYc-h1CI9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ComplexBoundaries"
      ],
      "metadata": {
        "id": "oT1JxmBJNX70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection"
      ],
      "metadata": {
        "id": "nuEYGpEkCJAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "data=datasets.load_boston()\n",
        "#print(data)\n",
        "boston = datasets.load_boston()\n",
        "X = boston.data\n",
        "Y = boston.target"
      ],
      "metadata": {
        "id": "eLmvFV8qNgtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "Zl6kZUdRNg14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(X)\n",
        "print(boston.feature_names)\n",
        "df.columns = boston.feature_names\n",
        "df[\"age_age\"] = df.AGE ** 2\n",
        "df.describe()\n",
        "X2 = df.values\n",
        "X2.shape"
      ],
      "metadata": {
        "id": "07AK-RtGNg6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection\n",
        "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, random_state = 0)\n",
        "X2_train, X2_test, Y2_train, Y2_test = model_selection.train_test_split(X2, Y, random_state = 0)"
      ],
      "metadata": {
        "id": "-QWBo5QLNg83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "alg1 = LinearRegression()\n",
        "alg2 = LinearRegression()"
      ],
      "metadata": {
        "id": "CXkkfRorNhAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "alg1 = LinearRegression()\n",
        "alg2 = LinearRegression()"
      ],
      "metadata": {
        "id": "ajUIwp4KNhRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alg1.fit(X_train, Y_train)\n",
        "alg2.fit(X2_train, Y2_train)"
      ],
      "metadata": {
        "id": "Kf7eRYY9O0_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = alg1.predict(X_test)\n",
        "train_score = alg1.score(X_train, Y_train)\n",
        "test_score = alg1.score(X_test, Y_test)\n",
        "print(\"Train Score: \", train_score)\n",
        "print(\"Test Score: \", test_score)\n",
        "\n",
        "train2_score = alg2.score(X2_train, Y2_train)\n",
        "test2_score = alg2.score(X2_test, Y2_test)\n",
        "print(\"Train2 Score: \", train2_score)\n",
        "print(\"Test2 Score: \", test2_score)"
      ],
      "metadata": {
        "id": "N4LKjkPWCJDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a6Q9bZb1O1Bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GradientDescent"
      ],
      "metadata": {
        "id": "K-kusjfWPu74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "CUW-A0yhO1EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.loadtxt(\"data.csv\", delimiter=\",\")\n",
        "data.shape"
      ],
      "metadata": {
        "id": "vy1m3lAmO1G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def step_gradient(points, learning_rate, m , c):\n",
        "    m_slope = 0\n",
        "    c_slope = 0\n",
        "    M = len(points)\n",
        "    for i in range(M):\n",
        "        x = points[i, 0]\n",
        "        y = points[i, 1]\n",
        "        m_slope += (-2/M)* (y - m * x - c)*x\n",
        "        c_slope += (-2/M)* (y - m * x - c)\n",
        "    new_m = m - learning_rate*m_slope\n",
        "    new_c = c - learning_rate*c_slope\n",
        "    return new_m, new_c"
      ],
      "metadata": {
        "id": "XSElctmoO1JZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gd(points, learning_rate, num_iterations):\n",
        "    m = 0\n",
        "    c = 0\n",
        "    for i in range(num_iterations):\n",
        "        m, c = step_gradient(points, learning_rate, m , c)\n",
        "        print(i, \" Cost: \", cost(points, m, c))\n",
        "    return m, c"
      ],
      "metadata": {
        "id": "vb3LEM4jO1L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cost(points, m, c):\n",
        "    total_cost = 0\n",
        "    M = len(points)\n",
        "    for i in range(M):\n",
        "        x = points[i, 0]\n",
        "        y = points[i, 1]\n",
        "        total_cost += (1/M)*((y - m*x - c)**2)\n",
        "    return total_cost"
      ],
      "metadata": {
        "id": "7TuPtHeyVIdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run():\n",
        "    data = np.loadtxt(\"data.csv\", delimiter=\",\")\n",
        "    learning_rate = 0.0001\n",
        "    num_iterations = 100\n",
        "    m, c = gd(data, learning_rate, num_iterations)\n",
        "    print(m, c)"
      ],
      "metadata": {
        "id": "lHZaW2NUVIjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run()"
      ],
      "metadata": {
        "id": "r7aBwR7DVOg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LAw0MkXUO1Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes"
      ],
      "metadata": {
        "id": "1mHiTYvXQQRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "def fit (x_train,y_train):\n",
        "  result={}\n",
        "  class_values= set(y_train) \n",
        "  for current_class in class_values:\n",
        "    result[class_values]={}\n",
        "    result[\"total_data\"]= len(y_train)\n",
        "    current_class_row=(y_train == current_class)\n",
        "    X_train_current=x_train[current_class_row]\n",
        "    Y_train_current=y_train[current_class_row]\n",
        "    num_feature = x_test.shape[1]\n",
        "    result[current_class][\"total_count\"]=len(Y_train_current)\n",
        "    for j in range(1, num_feature + 1 ):\n",
        "      result[current_class][j]={}\n",
        "      all_possible_values=set(x_train[:,j-1])\n",
        "      for current_value in all_possible_values:\n",
        "        result[current_class][j][current_value] = (X_train_current[:, j -1] == current_value).sum()\n",
        "  return result     \n"
      ],
      "metadata": {
        "id": "SFiNuvZ2CJGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_feature=5\n",
        "for j in range (1, num_feature +1):\n",
        "  print(j)"
      ],
      "metadata": {
        "id": "viY777A-QV9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BzD_lAh5QWF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes"
      ],
      "metadata": {
        "id": "uBmIjq1Ddvk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "def fit(X_train, Y_train):\n",
        "    result = {}\n",
        "    class_values = set(Y_train)\n",
        "    for current_class in class_values:\n",
        "        result[current_class] = {}\n",
        "        result[\"total_data\"] = len(Y_train)\n",
        "        current_class_rows = (Y_train == current_class)\n",
        "        X_train_current = X_train[current_class_rows]\n",
        "        Y_train_current = Y_train[current_class_rows]\n",
        "        num_features = X_train.shape[1]\n",
        "        result[current_class][\"total_count\"] = len(Y_train_current)\n",
        "        for j in range(1, num_features + 1):\n",
        "            result[current_class][j] = {}\n",
        "            all_possible_values = set(X_train[:, j - 1])\n",
        "            for current_value in all_possible_values:\n",
        "                result[current_class][j][current_value] = (X_train_current[:, j - 1] == current_value).sum()\n",
        "                \n",
        "    return result\n",
        "\n",
        "def probability(dictionary, x, current_class):\n",
        "    output = np.log(dictionary[current_class][\"total_count\"]) - np.log(dictionary[\"total_data\"])\n",
        "    num_features = len(dictionary[current_class].keys()) - 1;\n",
        "    for j in range(1, num_features + 1):\n",
        "        xj = x[j - 1]\n",
        "        count_current_class_with_value_xj = dictionary[current_class][j][xj] + 1\n",
        "        count_current_class = dictionary[current_class][\"total_count\"] + len(dictionary[current_class][j].keys())\n",
        "        current_xj_probablity = np.log(count_current_class_with_value_xj) - np.log(count_current_class)\n",
        "        output = output + current_xj_probablity\n",
        "    return output\n",
        "\n",
        "\n",
        "def predictSinglePoint(dictionary, x):\n",
        "    classes = dictionary.keys()\n",
        "    best_p = -1000\n",
        "    best_class = -1\n",
        "    first_run = True\n",
        "    for current_class in classes:\n",
        "        if (current_class == \"total_data\"):\n",
        "            continue\n",
        "        p_current_class = probability(dictionary, x, current_class)\n",
        "        if (first_run or p_current_class > best_p):\n",
        "            best_p = p_current_class\n",
        "            best_class = current_class\n",
        "        first_run = False\n",
        "    return best_class\n",
        "\n",
        "\n",
        "def predict(dictionary, X_test):\n",
        "    y_pred = []\n",
        "    for x in X_test:\n",
        "        x_class = predictSinglePoint(dictionary, x)\n",
        "        y_pred.append(x_class)\n",
        "    return y_pred\n",
        "\n"
      ],
      "metadata": {
        "id": "Um_QDWWpQWJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TBUinb08QWMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6v-H3dR7QWPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes with iris data "
      ],
      "metadata": {
        "id": "gezqTSQohvHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def fit(X_train, Y_train):\n",
        "    result = {}\n",
        "    class_values = set(Y_train)\n",
        "    for current_class in class_values:\n",
        "        result[current_class] = {}\n",
        "        result[\"total_data\"] = len(Y_train)\n",
        "        current_class_rows = (Y_train == current_class)\n",
        "        X_train_current = X_train[current_class_rows]\n",
        "        Y_train_current = Y_train[current_class_rows]\n",
        "        num_features = X_train.shape[1]\n",
        "        result[current_class][\"total_count\"] = len(Y_train_current)\n",
        "        for j in range(1, num_features + 1):\n",
        "            result[current_class][j] = {}\n",
        "            all_possible_values = set(X_train[:, j - 1])\n",
        "            for current_value in all_possible_values:\n",
        "                result[current_class][j][current_value] = (X_train_current[:, j - 1] == current_value).sum()\n",
        "                \n",
        "    return result\n",
        "\n",
        "\n",
        "def probability(dictionary, x, current_class):\n",
        "    output = np.log(dictionary[current_class][\"total_count\"]) - np.log(dictionary[\"total_data\"])\n",
        "    num_features = len(dictionary[current_class].keys()) - 1;\n",
        "    for j in range(1, num_features + 1):\n",
        "        xj = x[j - 1]\n",
        "        count_current_class_with_value_xj = dictionary[current_class][j][xj] + 1\n",
        "        count_current_class = dictionary[current_class][\"total_count\"] + len(dictionary[current_class][j].keys())\n",
        "        current_xj_probablity = np.log(count_current_class_with_value_xj) - np.log(count_current_class)\n",
        "        output = output + current_xj_probablity\n",
        "    return output\n",
        "\n",
        "\n",
        "def predictSinglePoint(dictionary, x):\n",
        "    classes = dictionary.keys()\n",
        "    best_p = -1000\n",
        "    best_class = -1\n",
        "    first_run = True\n",
        "    for current_class in classes:\n",
        "        if (current_class == \"total_data\"):\n",
        "            continue\n",
        "        p_current_class = probability(dictionary, x, current_class)\n",
        "        if (first_run or p_current_class > best_p):\n",
        "            best_p = p_current_class\n",
        "            best_class = current_class\n",
        "        first_run = False\n",
        "    return best_class\n",
        "\n",
        "\n",
        "def predict(dictionary, X_test):\n",
        "    y_pred = []\n",
        "    for x in X_test:\n",
        "        x_class = predictSinglePoint(dictionary, x)\n",
        "        y_pred.append(x_class)\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "def makeLabelled(column):\n",
        "    second_limit = column.mean()\n",
        "    first_limit = 0.5 * second_limit\n",
        "    third_limit = 1.5*second_limit\n",
        "    for i in range (0,len(column)):\n",
        "        if (column[i] < first_limit):\n",
        "            column[i] = 0\n",
        "        elif (column[i] < second_limit):\n",
        "            column[i] = 1\n",
        "        elif(column[i] < third_limit):\n",
        "            column[i] = 2\n",
        "        else:\n",
        "            column[i] = 3\n",
        "    return column\n",
        "\n",
        "\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "Y = iris.target\n",
        "\n",
        "\n",
        "for i in range(0,X.shape[-1]):\n",
        "    X[:,i] = makeLabelled(X[:,i])\n",
        "\n",
        "\n",
        "from sklearn import model_selection\n",
        "X_train,X_test,Y_train,Y_test = model_selection.train_test_split(X,Y,test_size=0.25,random_state=0)\n",
        "\n",
        "dictionary = fit(X_train,Y_train)\n",
        "\n",
        "Y_pred = predict(dictionary,X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(Y_test,Y_pred))\n",
        "print(confusion_matrix(Y_test,Y_pred))\n",
        "\n"
      ],
      "metadata": {
        "id": "CXtDN5ZzQWTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding probability for continues "
      ],
      "metadata": {
        "id": "o0Facl6Cl4Fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "clf=GaussianNB()\n",
        "clf.fit(X_train,Y_train)\n",
        "Y_pred=clf.predict(X_test)\n",
        "print(classification_report(Y_test, Y_pred))\n",
        "print(confusion_matrix(Y_test, Y_pred))"
      ],
      "metadata": {
        "id": "DQSiGQSvl254"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Classification using naive bayes "
      ],
      "metadata": {
        "id": "ft9g-0pIsBPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf=MultinomialNB()\n",
        "clf.fit(X_train,Y_train)\n",
        "Y_pred=clf.predict(X_test)\n",
        "print(classification_report(Y_test, Y_pred))\n",
        "print(confusion_matrix(Y_test, Y_pred))\n",
        "\n",
        "# :- it's not good looking data here "
      ],
      "metadata": {
        "id": "7j4byVDDl3Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eBSoSwmih27u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# KNN\n",
        "\n"
      ],
      "metadata": {
        "id": "c5B6KY1aIXaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "dataset = datasets.load_breast_cancer()\n",
        "dataset.target\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WYrBBIsHml7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset.data, dataset.target, test_size = 0.2, random_state = 0)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x4PjKtIoIkvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = KNeighborsClassifier()\n",
        "clf.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "4jmdINLPK-5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.score(X_test, Y_test)"
      ],
      "metadata": {
        "id": "rnsh3JcgIky3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V0KwozcaLFDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* cross validation \n"
      ],
      "metadata": {
        "id": "Tfgd0TatOjzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "q541y3aPLFMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris=datasets.load_iris()\n",
        "xtrain,ytrain,xtest,ytest= train_test_split(iris.data, iris.target, test_size=0.2)"
      ],
      "metadata": {
        "id": "9FA7l8KQLFPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf=LinearRegression()\n",
        "cross_val_score(clf, iris.data, iris.target, cv=KFold(5))\n",
        "#cross_val_score(clf, iris.data, iris.target, cv=KFold(3, True, 0))"
      ],
      "metadata": {
        "id": "Q_tCc2j0PZuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b18h2e6RPZ7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Finding optimal K"
      ],
      "metadata": {
        "id": "ioPxu77fXZjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "ErY9021dPbKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.load_breast_cancer()\n",
        "dataset.target"
      ],
      "metadata": {
        "id": "pELMq064XeKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset.data, dataset.target, test_size = 0.2, random_state = 0)\n",
        "\n"
      ],
      "metadata": {
        "id": "uVgKRiZ4Xo8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = KNeighborsClassifier()\n",
        "clf.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "TVcTF-WfXpCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.score(X_test, Y_test)"
      ],
      "metadata": {
        "id": "iigHk3n7XeSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_axis = []\n",
        "y_axis = []\n",
        "for i in range(1, 26, 2):\n",
        "    clf = KNeighborsClassifier(n_neighbors = i)\n",
        "    score = cross_val_score(clf, X_train, Y_train)\n",
        "    x_axis.append(i)\n",
        "    y_axis.append(score.mean())\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(x_axis, y_axis)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L04EP0vkYErr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* IMPLEMENT KNN"
      ],
      "metadata": {
        "id": "hR3zwQwK2ZiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "dataset = datasets.load_breast_cancer()\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset.data, dataset.target, test_size = 0.2, random_state = 0)\n",
        "\n",
        "\n",
        "clf = KNeighborsClassifier(n_neighbors=7)\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "clf.score(X_test, Y_test)\n",
        "\n",
        "def train(x, y):\n",
        "    return\n",
        "\n",
        "def predict_one(x_train, y_train, x_test, k):\n",
        "    distances = []\n",
        "    for i in range(len(x_train)):\n",
        "        distance = ((x_train[i, :] - x_test)**2).sum()\n",
        "        distances.append([distance, i])\n",
        "    distances = sorted(distances)\n",
        "    targets = []\n",
        "    for i in range(k):\n",
        "        index_of_training_data = distances[i][1]\n",
        "        targets.append(y_train[index_of_training_data])\n",
        "    return Counter(targets).most_common(1)[0][0]\n",
        "\n",
        "def predict(x_train, y_train, x_test_data, k):\n",
        "    predictions = []\n",
        "    for x_test in x_test_data:\n",
        "        predictions.append(predict_one(x_train, y_train, x_test, k))\n",
        "    return predictions\n",
        "\n",
        "\n",
        "y_pred = predict(X_train, Y_train, X_test, 7)\n",
        "accuracy_score(Y_test, y_pred)\n",
        "\n",
        "a = [1,0,1,1,1,1,0, 2]\n",
        "Counter(a).most_common(1)[0][0]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xJ39oLtn2ZB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Support Vectors Machine "
      ],
      "metadata": {
        "id": "y-H8cK3n0J1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn import svm, datasets\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "x = iris.data[:, 0:2]\n",
        "y = iris.target\n",
        "\n",
        "\n",
        "x_train,x_test, y_train, y_test = train_test_split(x, y)\n",
        "\n",
        "clf = svm.SVC(kernel = 'linear')\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "clf.score(x_test, y_test)\n",
        "\n",
        "def makegrid(x1, x2, h = 0.02):\n",
        "    x1_min, x1_max = x1.min() - 1, x1.max() + 1\n",
        "    x2_min, x2_max = x2.min() - 1, x2.max() + 1\n",
        "    a = np.arange(x1_min,x1_max,h)\n",
        "    b = np.arange(x2_min, x2_max, h)\n",
        "    xx, yy = np.meshgrid(a, b)\n",
        "    return xx, yy\n",
        "\n",
        "\n",
        "xx, yy = makegrid(x[:, 0], x[:, 1])\n",
        "predictions = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "plt.scatter(xx.ravel(), yy.ravel(), c = predictions)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P1z0TwW92ZNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a=np.arange(1,3,0.2)\n",
        "b=np.arange(4,6,0.2)\n",
        "xx,yy=np.meshgrid(a,b)\n",
        "(xx*yy*xx).shape[0]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V7gWScPp2ZQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Grid SearchCV\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bt6FjtNA5WMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "\n",
        "\n",
        "x_train,x_test, y_train, y_test = train_test_split(x, y)\n",
        "\n",
        "\n",
        "clf = KNeighborsClassifier()\n",
        "grid = {\"n_neighbors\":[3,5,7,9,11]}\n",
        "abc = GridSearchCV(clf, grid)\n",
        "abc.fit(x_train, y_train)\n",
        "\n",
        "abc.best_estimator_\n",
        "\n",
        "clf = svm.SVC()\n",
        "grid = {'C' : [1e2, 1e3, 5e3, 1e4, 5e4, 1e5],\n",
        "       'gamma' : [1e-3, 5e-4, 1e-4, 5e-3]}\n",
        "abc = GridSearchCV(clf, grid)\n",
        "abc.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "abc.best_estimator_\n",
        "\n"
      ],
      "metadata": {
        "id": "jmjdIHyk2ZS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e_00HF5MYEuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Support vectoer regrasioon "
      ],
      "metadata": {
        "id": "uDxYjXF39J-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "boston = datasets.load_boston()\n",
        "\n",
        "\n",
        "x = boston.data\n",
        "y = boston.target\n",
        "\n",
        "\n",
        "x_train,x_test, y_train, y_test = train_test_split(x, y, random_state = 0)\n",
        "\n",
        "clf = svm.SVR(kernel=\"rbf\")\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "clf.score(x_test, y_test)\n",
        "\n",
        "clf = svm.SVR(kernel=\"linear\")\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "clf.score(x_test, y_test)\n",
        "\n",
        "clf = svm.SVR()\n",
        "grid = {'C': [1e2,1e3, 5e3, 1e4, 5e4, 1e5],\n",
        "       'gamma': [1e-3, 5e-4, 1e-4, 5e-3]}\n",
        "abc = GridSearchCV(clf, grid)\n",
        "abc.fit(x_train, y_train)\n",
        "abc.best_estimator_\n",
        "\n",
        "abc.score(x_test, y_test)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ln-Q2THg6HiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying PCA to 2D data "
      ],
      "metadata": {
        "id": "Ej5PrnVgLgS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "4lczKuk36Ho1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1= np.array([1,2,3,4,5,6])\n",
        "x2=np.array([7.5,17,16,18,20,26])\n",
        "plt.scatter(x1,x2)\n",
        "plt.show()\n",
        "x=np.c_[x1,x2]\n",
        "x"
      ],
      "metadata": {
        "id": "OAj6paOZ-eiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PCA=PCA(n_components=2)\n",
        "x_tranforM=PCA.fit_transform(x)\n",
        "x_tranforM"
      ],
      "metadata": {
        "id": "66oTaBHT-ek1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PCA.components_\n",
        "x_approx=PCA.inverse_transform(x_tranforM)\n",
        "plt.scatter(x_approx[:,0],x_approx[:,1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YaIWdboyNA92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M-f2R5ChNA-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* Applying PCA 3D data "
      ],
      "metadata": {
        "id": "wQLGMiMyV9O1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as py\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "HmOnj6vbWhOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(2343243)"
      ],
      "metadata": {
        "id": "G9wJwjbdWg0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_vec1=np.array([0,0,0])\n",
        "cov_mat1=np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
        "class1=np.random.multivariate_normal(mean_vec1, cov_mat1,100)\n"
      ],
      "metadata": {
        "id": "rFxABXEWNBEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_vec2=np.array([1,1,1])\n",
        "cov_mat2=np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
        "class2=np.random.multivariate_normal(mean_vec1, cov_mat1,100)\n"
      ],
      "metadata": {
        "id": "4Dmr72L0WdoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D, proj3d\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "ax = fig.add_subplot(111,projection='3d')\n",
        "ax.plot(class1[:, 0], class1[:, 1], class1[:, 2], 'o')\n",
        "ax.plot(class2[:, 0], class2[:, 1], class2[:, 2], '^')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l8djpwdUWUPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = np.concatenate((class1, class2))"
      ],
      "metadata": {
        "id": "4xmMNjS2NBEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components = 2)\n",
        "transformed_data = pca.fit_transform(all_data)\n",
        "transformed_data"
      ],
      "metadata": {
        "id": "LubN_O-tZAgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca.components_"
      ],
      "metadata": {
        "id": "ZPQ8vXZEYE3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(transformed_data[0:100,0],transformed_data[0:100,1],\"o\")\n",
        "plt.plot(transformed_data[100:200,0],transformed_data[100:200,1],\"^\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y1R6TYpQZVTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_approx = pca.inverse_transform(transformed_data)\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "ax = fig.add_subplot(111,projection='3d')\n",
        "ax.plot(X_approx[:, 0], X_approx[:, 1], X_approx[:, 2], '^')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7ta4w32XZc-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = -0.409689\n",
        "b = 7.2827\n",
        "c = - 7.1008\n",
        "i = 10\n",
        "a * X_approx[i][0] + b* X_approx[i][1] + c * X_approx[i][2]\n"
      ],
      "metadata": {
        "id": "k6Mea-UBZcxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9jmzFr5hZtB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis on Breasr cancer Dataset"
      ],
      "metadata": {
        "id": "ZKwqz15Fe_iZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import decomposition, ensemble , datasets\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "3sGztZaqfDIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer=datasets.load_breast_cancer()\n"
      ],
      "metadata": {
        "id": "ZZQcOlmCvtsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=breast_cancer.data\n",
        "x.shape"
      ],
      "metadata": {
        "id": "ioEKF4BFvtnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc=StandardScaler()\n",
        "x_std=sc.fit_transform(x)\n",
        "x_train,x_test,y_train,y_test=train_test_split(x_std,breast_cancer.target, random_state=0)\n"
      ],
      "metadata": {
        "id": "pEYUqy3jfDi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "pca=decomposition.PCA(n_components=15)\n",
        "x_train_PCA=pca.fit_transform(x_train)\n",
        "x_test_PCA=pca.fit_transform(x_test)\n",
        "lr=linear_model.LogisticRegression()\n",
        "start=time.time()\n",
        "lr.fit(x_train,y_train)\n",
        "ending=time.time()\n",
        "print(ending-start)\n",
        "print(lr.score(x_test,y_test))"
      ],
      "metadata": {
        "id": "euW5aJpMxKSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# math bahind of PCA\n",
        "pca.explained_variance_"
      ],
      "metadata": {
        "id": "cvFvUnYDxKQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LET'S Code Our PCA"
      ],
      "metadata": {
        "id": "1ylJTE2uKVqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data_t=all_data.T\n",
        "cov=np.cov(all_data)\n",
        "cov.shape\n",
        "cov"
      ],
      "metadata": {
        "id": "1TY6XPMRxKNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eig_val, eig_vectores = np.linalg, eig(cov)\n",
        "eig_val_vector_pair = []\n",
        "for i in range(len(eig_val)):\n",
        "  eig_vec= eig_vectores[:, i]\n",
        "  eig_val_vector_pair.applend((eig_val[i], eig_vec))\n",
        "  eig_val_vector_pair.sort(reverse=True)\n",
        "  eig_val_vector_pair"
      ],
      "metadata": {
        "id": "xw0pRlHMNjT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca.components_\n",
        "pca.explained_variance_"
      ],
      "metadata": {
        "id": "uYFOpxttO2RD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Finding optimal Number of feature "
      ],
      "metadata": {
        "id": "fgeZ1munUC53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pca= decomposition.PCA()\n",
        "total = sum(pca.explained_variance_)\n",
        "k = 0\n",
        "current_variance=0\n",
        "while cureent_variance / total < 0.99:\n",
        "  current_variance + = pca.explained_variance_[k]\n",
        "  k= k+1\n",
        "k  \n"
      ],
      "metadata": {
        "id": "BNKZ97RTNs_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kxXrRUV5KsMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* PCA on olevitti images"
      ],
      "metadata": {
        "id": "N_UbSTfaYHO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "LxQF_RYMX-8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oliv = datasets.fetch_olivetti_faces()"
      ],
      "metadata": {
        "id": "hnMh9btWX_DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oliv.keys()"
      ],
      "metadata": {
        "id": "7va8ozT0YnBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oliv['data'].shape"
      ],
      "metadata": {
        "id": "McvIRKjKYnA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oliv['images'].shape"
      ],
      "metadata": {
        "id": "IGD_b9e-Ym75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8,8))\n",
        "for i in range (64):\n",
        "  ax=fig.add_subplot(8, 8,i+1)\n",
        "  ax.imshow(oliv.images[i], cmap= plt.cm.bone)\n",
        "plt.show()  "
      ],
      "metadata": {
        "id": "MPjm8D5QZu0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x= oliv.data\n",
        "y=oliv.target"
      ],
      "metadata": {
        "id": "CDy6K0V4Ym7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca=PCA()\n",
        "pca.fit(x)\n"
      ],
      "metadata": {
        "id": "2WfLwp9jbCZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca.components_.shape\n"
      ],
      "metadata": {
        "id": "MKyhdjpJbCZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k=0\n",
        "total=sum(pca.explained_variance_)\n",
        "currentsum=0\n",
        "while currentsum/total < 0.95:\n",
        "  currentsum += pca.explained_variance_[k]\n",
        "  k=k+1\n",
        "k  "
      ],
      "metadata": {
        "id": "sVMoVw_KbCgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=k, whiten=True)\n",
        "transformed_data=pca.fit_transform(x)\n",
        "transformed_data.shape"
      ],
      "metadata": {
        "id": "sYhTJ5jcbCgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Reproducing Images "
      ],
      "metadata": {
        "id": "qdRXH3f4dGmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_approx=pca.inverse_transform(transformed_data)\n",
        "x_approx.shape"
      ],
      "metadata": {
        "id": "9VVX3XU_Ym1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_approx_images=x_approx.reshape((400, 64, 64))"
      ],
      "metadata": {
        "id": "rPyTUKLvcsca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8,8))\n",
        "for i in range (64):\n",
        "  ax=fig.add_subplot(8, 8,i+1)\n",
        "  ax.imshow(oliv.images[i], cmap= plt.cm.bone)\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "Bk-eFtj5YmjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f-_jJ2hFYmil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Eigenfaces"
      ],
      "metadata": {
        "id": "c9IDAW1felzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eigenv= pca.components_\n",
        "eigenv.shape"
      ],
      "metadata": {
        "id": "6lUIVP6cerKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eigenfaces=eigenv.reshape((123, 64, 64))"
      ],
      "metadata": {
        "id": "8KA8RCv0esS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8,8))\n",
        "for i in range (64):\n",
        "  ax=fig.add_subplot(8, 8,i+1)\n",
        "  ax.imshow(eigenfaces[i], cmap= plt.cm.bone)\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "gasqndaEesTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lIgrRcO6esYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Classifaction of LFW Images "
      ],
      "metadata": {
        "id": "KPX_4vGEhacB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "WZzhXlDresgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lfw= datasets.fetch_lfw_people(min_faces_per_person=100, resize=0.4)\n"
      ],
      "metadata": {
        "id": "7NsgpcQ9hh1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lfw.keys()\n"
      ],
      "metadata": {
        "id": "xD8-nIhZhh42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lfw.data.shape"
      ],
      "metadata": {
        "id": "-Akmvcwghh9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lfw.images.shape"
      ],
      "metadata": {
        "id": "Qqpg-7RRiKuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8,8))\n",
        "for i in range (64):\n",
        "  ax=fig.add_subplot(8, 8,i+1)\n",
        "  ax.imshow(lfw.images[i], cmap= plt.cm.bone)\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "TXJh92fUiKu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = lfw.data, lfw.target\n",
        "lfw=PCA()\n",
        "lfw.fit(x)"
      ],
      "metadata": {
        "id": "h0p28DK9iKz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k=0\n",
        "total=0\n",
        "\n",
        "while total < 0.99:\n",
        "  total += total + lfw.explained_variance_ratio_[k]\n",
        "  k=k+1\n",
        "k  "
      ],
      "metadata": {
        "id": "maLHmmFUi0CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HYOlXW7ui0MZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Natural language Processing "
      ],
      "metadata": {
        "id": "AZpE9J7MgKbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "m738sJ7tgNtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text= \"does This thong Really work .\"\n"
      ],
      "metadata": {
        "id": "aF4A8Tx0htuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "7PfAqrBgilf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "metadata": {
        "id": "SceMPCHUht9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words =word_tokenize(sample_text.lower())"
      ],
      "metadata": {
        "id": "XzbWhYdChuCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "uSjMv1aqhuDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "o73BlAIFmRuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop = stopwords.words('english')\n",
        "stop"
      ],
      "metadata": {
        "id": "eAlP5zUKi_XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "punctuations = list(string.punctuation)\n",
        "stop= stop + punctuations\n"
      ],
      "metadata": {
        "id": "DxLqAA3wmdWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_words=[w for w in words if not w in stop]\n",
        "clean_words"
      ],
      "metadata": {
        "id": "qB0urg8NjQjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp = \"Hey! how's work going ?.\""
      ],
      "metadata": {
        "id": "7QHWfewGphtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "metadata": {
        "id": "tMDtATyioQzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words =word_tokenize(sp)\n",
        "words"
      ],
      "metadata": {
        "id": "I8IiAmh8meCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YISnT7iyr1ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* stemming"
      ],
      "metadata": {
        "id": "pKT2Togur7gJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "o8xE0uVUr1vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stem_words= [\"play\", \"playing\", \"player\", \"played\", \"happying\", \"briefly\"]\n",
        "ps=PorterStemmer()\n",
        "stemed_words=[ps.stem(w) for w in stem_words]\n",
        "stemed_words"
      ],
      "metadata": {
        "id": "0UmPT4hbsBCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* port of speech"
      ],
      "metadata": {
        "id": "3ZKsXdxtuKo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag"
      ],
      "metadata": {
        "id": "dAB4ZJ4puOMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import state_union"
      ],
      "metadata": {
        "id": "_6eeA2gSuf7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('state_union')"
      ],
      "metadata": {
        "id": "c-94dBHjvJtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=state_union.raw(\"2006-GWBush.txt\")"
      ],
      "metadata": {
        "id": "I6NYMiCPuO6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "id": "l4HUXAcAuPKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "V0jNeAZ4vyjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos=pos_tag(word_tokenize(text))\n",
        "pos"
      ],
      "metadata": {
        "id": "RZt1e9ZJvSld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t=\"raj went for a walk\"\n",
        "p=pos_tag(word_tokenize(t))\n",
        "p"
      ],
      "metadata": {
        "id": "bzhKU6rcvUCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t=\"JJ stand fo r \"\n",
        "p=pos_tag(word_tokenize(t))\n",
        "p"
      ],
      "metadata": {
        "id": "4YUkGiVWzFgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Lemmatization"
      ],
      "metadata": {
        "id": "6jgzMLg8wHJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "r2ECOFiGwGR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer= WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "14xI3A4k1uXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " import nltk\n",
        " nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "yyJKe7TD2Iqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "Jtu5JFxB2Vkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"good\", pos=\"a\")"
      ],
      "metadata": {
        "id": "1XkDFXVi11Ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"excellent\", pos=\"n\")"
      ],
      "metadata": {
        "id": "G7HvT_D_20rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"painting\", pos=\"v\")"
      ],
      "metadata": {
        "id": "lWyVz3pD280W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"thing\", pos=\"n\")"
      ],
      "metadata": {
        "id": "c1PXZa0y3DkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus.reader import wordnet\n",
        "def get_simple_pos(tag):\n",
        "  if tag.startswith('J'):\n",
        "    return wordnet.Adj\n",
        "  elif tag.startswith('V'):\n",
        "    return wordnet.VERB\n",
        "  elif tag.startswith('N'):\n",
        "    return wordnet.NOUN\n",
        "  elif tag.startswith('R'):\n",
        "    return wordnet.ADV\n",
        "  else:\n",
        "    return wordnet.NOUN        "
      ],
      "metadata": {
        "id": "B4ILSexh2vF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-5uan8Jy4VoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Movie Reviews Dataset"
      ],
      "metadata": {
        "id": "kv4NwA2OGInS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import movie_reviews"
      ],
      "metadata": {
        "id": "uYuVyk_WF4of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('movie_reviews')"
      ],
      "metadata": {
        "id": "lvpcws4OHCXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_reviews.categories()"
      ],
      "metadata": {
        "id": "MVI3P5BLGh_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# movie_reviews.fileids()\n",
        "movie_reviews.fileids('neg')"
      ],
      "metadata": {
        "id": "3yOsRYQWHIoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_reviews.words(movie_reviews.fileids()[5])"
      ],
      "metadata": {
        "id": "grw1RstXHZ6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Movie Reviews Dats Cleaning"
      ],
      "metadata": {
        "id": "dGyMBKEUHzRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import movie_reviews"
      ],
      "metadata": {
        "id": "Lga5Xtt5LaVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_reviews.words(movie_reviews.fileids()[5])"
      ],
      "metadata": {
        "id": "eP3zwzZ1L9Dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "documents = []\n",
        "for category in movie_reviews.categories():\n",
        "  for fileid in movie_reviews.fileids(category):\n",
        "    documents.append((movie_reviews.words(fileid), category))\n",
        "documents[0:5]    "
      ],
      "metadata": {
        "id": "VX66LG8jIY7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.shuffle(documents)\n",
        "documents[0:5]"
      ],
      "metadata": {
        "id": "px69woZ0MhkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer=WordNetLemmatizer"
      ],
      "metadata": {
        "id": "qIWWPQ17NRO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus.reader import wordnet\n",
        "def get_simple_pos(tag):\n",
        "  if tag.startswith('J'):\n",
        "    return wordnet.Adj\n",
        "  elif tag.startswith('V'):\n",
        "    return wordnet.VERB\n",
        "  elif tag.startswith('N'):\n",
        "    return wordnet.NOUN\n",
        "  elif tag.startswith('R'):\n",
        "    return wordnet.ADV\n",
        "  else:\n",
        "    return wordnet.NOUN "
      ],
      "metadata": {
        "id": "ivMUq0OXN0qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "J01EfdSuOny7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "w=\"better\"\n",
        "pos_tag([w])"
      ],
      "metadata": {
        "id": "QrRrGcOdN4c8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "hqhLZvp2SS8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.tokenize.sonority_sequencing import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "import string \n",
        "stops= set(stopwords.words('english'))\n",
        "punctuations=list(string.punctuation)\n",
        "stops.update(punctuation)\n",
        "stops, string.punctuation"
      ],
      "metadata": {
        "id": "zOsR7upDPOoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_review(words):\n",
        "  output_words=[]\n",
        "  for w in words:\n",
        "    if w.lower() not in stops:\n",
        "      pos=pos_tag([w])\n",
        "      clean_word=lemmatizer.lemmatize(w, pos=get_simple_pos(pos[0][1]))\n",
        "      output_words.append(clean_word.lower()) \n",
        "  return output_words    "
      ],
      "metadata": {
        "id": "mEAjmiUrMxlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents=[(clean_review(document), category) for document, category in documents]"
      ],
      "metadata": {
        "id": "bB6GBTH2QR6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents[0]"
      ],
      "metadata": {
        "id": "47fIg1M4Slxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Buliding feature Set"
      ],
      "metadata": {
        "id": "eZ9mY5XuTsvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "traning_documents=documents[0:1500]\n",
        "testing_documents=documents[1500:0]"
      ],
      "metadata": {
        "id": "6-tuHO9zULpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=[1,2]\n",
        "b=[3,4]\n",
        "a+=b\n",
        "a"
      ],
      "metadata": {
        "id": "FPUAGOg7UiAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_words=[]\n",
        "for doc in traning_documents:\n",
        "  all_words += doc[0]\n",
        "all_words "
      ],
      "metadata": {
        "id": "-JwTn0dwTxaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "otciMpk-U4bZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq=nltk.FreqDist(all_words)\n",
        "common=freq.most_common(3000)\n",
        "features= [i(0) for i in common]\n",
        "features"
      ],
      "metadata": {
        "id": "BGKNZQ6wU754"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feature_dict(words):\n",
        "  current_features={}\n",
        "  word_set=set(words)\n",
        "  for w in features:\n",
        "    current_features[w] = w in word_set\n",
        "  return current_features  "
      ],
      "metadata": {
        "id": "oeYZwpesVn0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output=get_feature_dict(traning_documents[0][1])\n",
        "output"
      ],
      "metadata": {
        "id": "OkuVY6bJYAAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traning_data=[(get_feature_dict(doc), category) for doc, category in traning_documents]\n",
        "testing_data=[(get_feature_dict(doc), category) for doc, category in traning_documents]"
      ],
      "metadata": {
        "id": "KSCjYX7yYMBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data[0]"
      ],
      "metadata": {
        "id": "kqD7ZHR8Y3a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BBvywmnVaL7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* classfication using nltk naivebays classifier"
      ],
      "metadata": {
        "id": "3-zFbF-GaAyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import NaiveBayesClassifier"
      ],
      "metadata": {
        "id": "X74BCnbRaUGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier=NaiveBayesClassifier.train(traning_data)"
      ],
      "metadata": {
        "id": "EUPwFizGahZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.classify.accuracy(classifier, testing_data)"
      ],
      "metadata": {
        "id": "b_lOQnvEaq8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Natural Language Processing (NLP) using sklearn "
      ],
      "metadata": {
        "id": "7LHsPsMObL2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\"\" NLTK array[ \n",
        " #   tuple\n",
        "  #  (\n",
        "   #     features\n",
        "    # dict{\n",
        "     #    f1:\n",
        "      #    f2:\n",
        "     #}\n",
        "    #)\n",
        "#]\"\"\n",
        "# NLTK model"
      ],
      "metadata": {
        "id": "UVlFMwQlbe6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk import NaiveBayesClassifier\n",
        "classfier.show_most_informative_features(15)"
      ],
      "metadata": {
        "id": "yAnlET4y7bzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from nltk.classify.scikitlearn import SklearnClassifier"
      ],
      "metadata": {
        "id": "WyBjxjzA8rcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc=SVC()\n",
        "classifier_sklearn=SklearnClassifier(svc)"
      ],
      "metadata": {
        "id": "YBtOmuMf9BEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_sklearn.train(traning_data)"
      ],
      "metadata": {
        "id": "l3MlZxi09SOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.classify.accuracy(classifier_sklearn, testing_data)"
      ],
      "metadata": {
        "id": "WVsbR9jN9qGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "-dVj8bbQ-I46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfc=RandomForestClassifier\n",
        "classifier_sklearn=SklearnClassifier"
      ],
      "metadata": {
        "id": "-uoI_RWG-WnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_sklearn.train(traning_data)"
      ],
      "metadata": {
        "id": "CPUqYAp1-kT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.classify.accuracy(classifier_sklearn, testing_data)"
      ],
      "metadata": {
        "id": "7NeO7wSC-rzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Count Vectorizer"
      ],
      "metadata": {
        "id": "A4Gx2PSB_Hp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer=WordNetLemmatizer\n",
        "def clean_review(self,words):\n",
        "  output_words=[]\n",
        "  for w in words:\n",
        "    if w.lower() not in stops:\n",
        "      pos = pos_tag([w])\n",
        "      clean_words= lemmatizer.lemmatize(w, pos = get_simple_pos(pos[0][1]))\n",
        "      output_words.append(clean_word.lower()) \n",
        "  return output_words\n"
      ],
      "metadata": {
        "id": "BG-VnZ2e_ia9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "wn=nltk.WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "BTg2aJtcDHSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer=WordNetLemmatizer"
      ],
      "metadata": {
        "id": "iOS02OE5EZAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents=[(clean_review(document), category) for document, category in documents]"
      ],
      "metadata": {
        "id": "piVUwmhB_qMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "fDrG1XhmGBOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set={\"the shy is blue\", \"the sun in bright\"}\n",
        "count_vec= CountVectorizer(max_features=3)\n",
        "a=count_vec= count_vec.fit_transform(train_set)\n",
        "a.todense()"
      ],
      "metadata": {
        "id": "3eL-wGZMGbFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_vec.get_feature_names()"
      ],
      "metadata": {
        "id": "IOlNX56lHSY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " categories = [category for document , category in documents]"
      ],
      "metadata": {
        "id": "UyfcpfNxCK2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_documents=[\" \".join(document) for document, category in documents]"
      ],
      "metadata": {
        "id": "aftvCM9mQ2UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split(text_documents, catgories)"
      ],
      "metadata": {
        "id": "nOMeJ_lCRHO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_vec=CountVectorizer(max_features=2000)\n",
        "x_train_features=count_vec.fit_tranform(x_train)\n",
        "x_train_features.todense()"
      ],
      "metadata": {
        "id": "M3a34FJmRWHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_vec.get_features:_names()"
      ],
      "metadata": {
        "id": "tolGDU68Rium"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features=count_vec.tranform(x_test)"
      ],
      "metadata": {
        "id": "gEXy0mhGSNEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* sklearn classfiers and N-gram"
      ],
      "metadata": {
        "id": "JRaM1O3eUwps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_vec=CountVectorizer(max_features=2000, ngram=(2,3))\n",
        "x_train_features=count_vec.fit_tranform(x_train)\n",
        "x_train_features.todense()"
      ],
      "metadata": {
        "id": "9lXmqlr_U3nR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* TF &IDF"
      ],
      "metadata": {
        "id": "UKP-bQ1HX8uQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fr8CFxjNYCt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KxQrASg6Yprz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network"
      ],
      "metadata": {
        "id": "jZ4GI-pHYqcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "notA93DaYutA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris=datasets.load_iris()"
      ],
      "metadata": {
        "id": "hWC-webJZDxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=iris.data\n",
        "y=iris.target"
      ],
      "metadata": {
        "id": "N2EPvmBnZJ-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y)"
      ],
      "metadata": {
        "id": "2TfvlllDZP6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "wpznXPyjZlEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "NVGcqFzdZnnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(hidden_layer_sizes=(20,), max_iter= 3000)\n",
        "clf.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "7Z4_euYBZw1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "wvS8T3snZ77U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(clf.coefs_)"
      ],
      "metadata": {
        "id": "6Y8nh53XabJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.coefs_[0].shape, clf.coefs_[1].shape"
      ],
      "metadata": {
        "id": "-ErgFWwgaxEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.intercepts_[0].shape,  clf.intercepts_[1].shape"
      ],
      "metadata": {
        "id": "cesoS4Zpa7M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aPSMt9c-7Q5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Forward Propagation"
      ],
      "metadata": {
        "id": "70GQjfaW7uz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "pN2VnR2l73pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x= np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y=np.array([[0,0,0,1]]).T\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "id": "F6D-hWKO750Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sig(z):\n",
        "  return 1/(1 + np.exp(-z))    "
      ],
      "metadata": {
        "id": "HRuhHdki8VEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dervative sig function \n",
        "def derivativesig(z):\n",
        "  return sig(z)*(1-sig(z))"
      ],
      "metadata": {
        "id": "QdkE_4x9DRxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# no hidden layer weights\n",
        "weights= 2* np.random.random((2,1)) -1 \n",
        "bias= 2 * np.random.random(1) - 1\n",
        "lr= 0.001\n",
        "weights, bias"
      ],
      "metadata": {
        "id": "6qrcJfsf8kCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forword propagation without any hidden layer \n",
        "output0 = x\n",
        "output = sig(np.dot(output0, weights) + bias)\n",
        "output"
      ],
      "metadata": {
        "id": "EQDQvEqJ8wVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forword Propagation 2"
      ],
      "metadata": {
        "id": "ecqJCiE-94-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wh= 2* np.random.random((2,2)) - 1\n",
        "bh= 2* np.random.random((1,2)) -1 \n",
        "wo= 2* np.random.random((2,1)) -1\n",
        "bo=2* np.random.random((1,1)) -1  "
      ],
      "metadata": {
        "id": "vj1ogCi2-Dax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output0=x\n",
        "outputHidden = sig(np.dot(output0, wh) + bh)\n",
        "output= sig(np.dot(outputHidden, wo) + bo)\n",
        "output\n"
      ],
      "metadata": {
        "id": "iaA_bT3PAKIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fzjWJ9jVBHzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* implement a simple Neural Network"
      ],
      "metadata": {
        "id": "y22GWKj6N0iX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for iter in range(10000):\n",
        "  output0=x\n",
        "  outputHidden = sig(np.dot(output0, wh) + bh)\n",
        "  output= sig(np.dot(outputHidden, wo) + bo)\n",
        "  first_term=output - y\n",
        "  input_for_last_layer=np.dot(output0, weights) + bias\n",
        "  second_term= derivativesig(input_for_last_layer)\n",
        "  first_two=first_term * second_term\n",
        "  first_two.shape\n",
        "\n",
        "  changes= np.array([[0,0],[0,0]])\n",
        "\n",
        "  for i in range(2):\n",
        "    for j in range(4):\n",
        "      changes[i][0] +=first_two[j][0] * output0[j][i]\n",
        "  weights = weights - lr*changes\n",
        "  bias_change= 0.0\n",
        "  for j in range(4):\n",
        "    bias_change += first_two[j][0] * 1\n",
        "  bias= bias - lr * bias_change\n",
        "output= sig(np.dot(x, weights) + bias)\n",
        "weights, bias, output  \n",
        " \n"
      ],
      "metadata": {
        "id": "4xvTbLSTN9Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* optimizing our code using vector "
      ],
      "metadata": {
        "id": "EVCzk9D-UPfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for iter in range(10000):\n",
        "  output0=x\n",
        "  outputHidden = sig(np.dot(output0, wh) + bh)\n",
        "  output= sig(np.dot(outputHidden, wo) + bo)\n",
        "  first_term=output - y\n",
        "  input_for_last_layer=np.dot(output0, weights) + bias\n",
        "  second_term= derivativesig(input_for_last_layer)\n",
        "  first_two=first_term * second_term\n",
        "  first_two.shape\n",
        "\n",
        "  changes= np.dot(output0.T, first_two)\n",
        "  weights = weights - lr*changes\n",
        "  bias_change= np.sum(first_two)\n",
        "  \n",
        "  bias= bias - lr * bias_change\n",
        "output= sig(np.dot(x, weights) + bias)\n",
        "weights, bias, output  "
      ],
      "metadata": {
        "id": "tVHk5S09UVNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Neural Network one Hidden Layer"
      ],
      "metadata": {
        "id": "_oWJWyls84jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "yu3cflpb9ATA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y=np.array([[0,1,1,0]]).T\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "id": "grlOtcOc9FrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sig(z):\n",
        "  return 1/(1 + np.exp(-z))"
      ],
      "metadata": {
        "id": "kI1bJAZq92ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def derivativesig(z):\n",
        "  return sig(z)* (1- sig(z))"
      ],
      "metadata": {
        "id": "vxZNJS4o-GQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one hidden layer weights\n",
        "wh= 2* np.random.random((2, 2)) - 1\n",
        "bh= 2* np.random.random((1, 2)) -1\n",
        "wo= 2* np.random.random((2,1)) - 1\n",
        "bo= 2* np.random.random((1,1)) - 1\n",
        "lr= 0.1  "
      ],
      "metadata": {
        "id": "Fie_nu0J-W3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward propagation with one hidden layer \n",
        "\n",
        "for iter in range(10000):\n",
        "  output0= x\n",
        "  inputHidden = sig(np.dot(output0, wh) + bh)\n",
        "  outputHidden = sig(inputHidden)\n",
        "  inputForOutputLayer= np.dot(outputHidden, wo) + bo\n",
        "  output=sig(inputForOutputLayer)\n",
        "\n",
        "  first_term_output_layer= output - y\n",
        "  second_term_output_layer= derivativesig(inputForOutputLayer)\n",
        "  first_two_output_layer= first_term_output_layer* second_term_output_layer\n",
        "\n",
        "  first_term_hidden_layer = np.dot(first_two_output_layer, wo.T)\n",
        "  second_term_hidden_layer= derivativesig(inputHidden)\n",
        "  first_two_hidden_layer= first_term_hidden_layer * second_term_hidden_layer\n",
        "\n",
        "  changes_output = np.dot(outputHidden.T, first_two_output_layer)\n",
        "  changes_output_bias= np.sum(first_two_hidden_layer, axis=0, keepdims=True)\n",
        "\n",
        "  changes_hidden = np.dot(output0.T, first_two_hidden_layer)\n",
        "  changes_hidden_bias= np.sum(first_two_hidden_layer, axis=0, keepdims=True)\n",
        "  wo = wo - lr * changes_output\n",
        "  bo = bo - lr * changes_output_bias\n",
        "\n",
        "  wh= wh - lr * changes_hidden\n",
        "  bh= bh - lr * changes_hidden_bias\n",
        "\n",
        "output0= x\n",
        "inputHidden = sig(np.dot(output0, wh) + bh)\n",
        "outputHidden = sig(inputHidden)\n",
        "inputForOutputLayer= np.dot(outputHidden, wo) + bo\n",
        "output=sig(inputForOutputLayer)\n",
        "output, wh, bh, wo, bo"
      ],
      "metadata": {
        "id": "g0V1Ksm5_OwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "61i9RInI_6Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TensorFlow"
      ],
      "metadata": {
        "id": "nrS30KZSKpSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "sh3tCFsqKulM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a= tf.constant(5)\n",
        "print(a)"
      ],
      "metadata": {
        "id": "XNB48MhNO3XA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b=tf.constant(10)\n",
        "c=tf.add(a,b)\n",
        "print(c)"
      ],
      "metadata": {
        "id": "EUyAO-ffPJMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var1=tf.Variable(20)\n",
        "print(var1)"
      ],
      "metadata": {
        "id": "iZBYHDanPJ_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var2=tf.Variable([[1,2],[3,4]])\n",
        "var3=tf.Variable([[5,6],[7,8]])\n",
        "print(tf.matmul(var2,var3))"
      ],
      "metadata": {
        "id": "EqBkNqNiP_p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "iHVPnNSxQh4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Load MNIST process the datasets"
      ],
      "metadata": {
        "id": "K_ET4o-eRNLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "Y_hSPsA6RTeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "zdb8ckkYRtkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[0])\n",
        "plt.show()\n",
        "print(y_train[0])"
      ],
      "metadata": {
        "id": "PUv13wF3SOSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=x_train.reshape(x_train.shape[0], -1)/255.0\n",
        "x_test=x_test.reshape(x_test.shape[0], -1)/255.0\n",
        "y_train=tf.keras.utils.to_categorical(y_train)\n",
        "y_test=tf.keras.utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "rWMu9C1KSqhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "PKqy0odyTw2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Model Architecture and \n",
        "bulding Model using sequential"
      ],
      "metadata": {
        "id": "mxMF0CEqWc34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "LmUH7WbTWnaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.api._v2.keras import activations\n",
        "model=Sequential()\n",
        "model.add(Dense(256, activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "r8x_Q5W_aDGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8AaD-jMxbjvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=10, batch_size=1024)"
      ],
      "metadata": {
        "id": "2MjVD7Bzdjkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "fWFQzzrLeDGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "o7E385x1eNoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import concatenate, Input"
      ],
      "metadata": {
        "id": "s3DU3B3FgrZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input=Input(shape = [784,])\n",
        "hidden_1 = Dense(256, activation='relu')(input)\n",
        "hidden_2= Dense(256, activation='relu')(hidden_1)\n",
        "hidden_3=Dense(256, activation='relu')(input)\n",
        "concat = concatenate([hidden_2, hidden_3])\n",
        "output=Dense(10, activation='softmax')(concat)\n",
        "model=Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "pYbTXkVahjgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=512)"
      ],
      "metadata": {
        "id": "u1RWFHyfojPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "bUL3_cMEpMIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Create Custom Layers"
      ],
      "metadata": {
        "id": "rP8c3S0bqnFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "lhQYFmoVqsiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLayer(layers.Layer):\n",
        "  def __init__(self, units, input_dim, activation):\n",
        "     super(MyLayer, self).__init__()\n",
        "     w_init=tf.random_normal_initializer()\n",
        "     self.w=tf.Variable(initial_value=w_init(shape=(input_dim, units), dtype='float32'), trainable=True)\n",
        "     b_init=tf.random_normal_initializer()\n",
        "     self.b=tf.Variable(initial_value=b_init(shape=(units), dtype='float32'), trainable=True)\n",
        "     self.activation=activation\n",
        "  def call(self, input):\n",
        "    linear_op=tf.add(tf.matmul(inputs, self.w), self.b)\n",
        "    if self.activation == 'relu':\n",
        "      return tf.nn.relu(linear_op)\n",
        "    elif self.activation == 'softmax':\n",
        "      return tf.nn.softmax(linear_op)     "
      ],
      "metadata": {
        "id": "GV5vfoCerD2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* custom model "
      ],
      "metadata": {
        "id": "Ji_rm_uHwMzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, n_input, n_hidden1, n_hidden2, n_classes):\n",
        "     super(MyModel, self).__init__()\n",
        "     self.layer1=MyModel(n_hidden1, n_input, 'relu')\n",
        "     self.layer2=MyModel(n_hidden2, n_hidden1, 'rulu')\n",
        "     self.out_layer=MyModel(n_classes, n_hidden2, 'softmax')\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    x=self.layer1(inputs) \n",
        "    x=self.layer2(x)\n",
        "    return self.out_layer(x)\n"
      ],
      "metadata": {
        "id": "RLhkFejcuRnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=MyModel(784, 256, 256, 10)"
      ],
      "metadata": {
        "id": "0P2C30UZwLTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', matrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Ff_hn4RgwwZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=10, batch_size=512)"
      ],
      "metadata": {
        "id": "vvI-bIXCxH0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "yWGdnhooxWcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# keras"
      ],
      "metadata": {
        "id": "HQwLpQtZSYVP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* flow of code in keras"
      ],
      "metadata": {
        "id": "bLJv0fwpUASA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "o_f_MWe2Sfq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "cancer = datasets.load_breast_cancer()\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size = 0.2, random_state = 0)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ],
      "metadata": {
        "id": "Efc_6cNjeOwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# layer\n",
        "model=Sequential()\n",
        "layer1= Dense(units=32, activation='relu', input_dim=30)\n",
        "model.add(layer1)\n",
        "model.add(Dense(units=16, activation='relu'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "JbqCbZUxV3cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "BjmUG0erX99W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit function\n",
        "\n",
        "model.fit(x_train, y_train, epochs=20, batch_size = 50, validation_data=(x_test, y_test))\n",
        "     "
      ],
      "metadata": {
        "id": "vzNBY08gc2P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test)\n",
        "score = model.evaluate(x_test, y_test)\n",
        "score"
      ],
      "metadata": {
        "id": "BKje_WoPeVTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN MNIST DATA"
      ],
      "metadata": {
        "id": "XXDL3z0NSnYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Qj9tywN5Sugp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import input_data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist=input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "metadata": {
        "id": "a5yUWsaFSzlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "mnist = tfds.load(name='mnist')"
      ],
      "metadata": {
        "id": "tkZU17M7WCBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_width=28\n",
        "input_height=28\n",
        "input_channels=1\n",
        "input_pixels=784\n",
        "\n",
        "n_conv1=32\n",
        "n_conv2=64\n",
        "stride_conv1=1\n",
        "stride_conv2=1\n",
        "conv1_k=5\n",
        "conv2_k=5\n",
        "max_pool1_k=2\n",
        "max_pool2_k=2\n",
        "\n",
        "n_hidden=1024\n",
        "n_out=10\n",
        "input_size_to_hidden= (input_width//(max_pool1_k * max_pool2_k)) * (input_height//(max_pool1_k * max_pool2_k)) * n_conv2"
      ],
      "metadata": {
        "id": "BeOsmjQGWSYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights={\n",
        "    \"wc1\" : tf.Variable(tf.random.normal([conv1_k,conv1_k, input_channels, n_conv1])),\n",
        "    \"wc2\" : tf.Variable(tf.random.normal([conv2_k,conv2_k, n_conv1, n_conv2])),\n",
        "    \"wh1\" : tf.Variable(tf.random.normal([input_size_to_hidden, n_hidden])),\n",
        "    \"wo\"  : tf.Variable(tf.random.normal([n_hidden, n_out]))\n",
        "}\n",
        "biases= {\n",
        "    \"bc1\": tf.Variable(tf.random.normal([n_conv1])),\n",
        "    \"bc2\": tf.Variable(tf.random.normal([n_conv2])),\n",
        "    \"bh1\": tf.Variable(tf.random.normal([n_hidden])),\n",
        "    \"bo\":  tf.Variable(tf.random.normal([n_out])),\n",
        "}"
      ],
      "metadata": {
        "id": "gm7N84p6W-d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#. convolution and maxpool function \n",
        "\n",
        "def conv(x, weights,biases,strides=1):\n",
        "  out=tf.nn.conv2d(x, weights, padding=\"SAME\", strides=[1,strides, strides, 1])\n",
        "  out=tf.nn.relu(out)\n",
        "  return out\n",
        "def maxpooling(x, k=2):\n",
        "  return tf.nn.max_pool(x, padding=\"SAME\", ksize=[1, k, k,1], strides=[1,k,k,1])  "
      ],
      "metadata": {
        "id": "WegpVNH6lwcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def cnn(x, weights, biases):\n",
        "  x = tf.reshape(x, shape=[-1 ,input_height,input_width, input_channels])\n",
        "  conv1 = conv(x,weights['wc1'],biases['bc1'])\n",
        "  conv1_pool= maxpooling(conv1, max_pool1_k)\n",
        "\n",
        "  conv2= conv(conv1_pool, weights['wc2'], biases['bc2'])\n",
        "  conv2_pool=maxpooling(conv2, max_pool2_k)\n",
        "\n",
        "  hidden_input= tf.reshape(conv2_pool, shape=[-1,input_size_to_hidden])\n",
        "  hidden_output_before_activation= tf.add(tf.matmul(hidden_input, weights['wh1']), biases['bh1'])\n",
        "  hidden_output= tf.nn.relu(hidden_output_before_activation)\n",
        "\n",
        "  output= tf.add(tf.matmul(hidden_output, weights['wo']), biases['bo'])\n",
        "  return output\n"
      ],
      "metadata": {
        "id": "k394jyezgtqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = tf.compat.v1.placeholder(\"float\",[None,input_pixels])\n",
        "y= tf.compat.v1.placeholder(tf.int32,[None,n_out])\n",
        "pred= cnn(x, weights, biases)"
      ],
      "metadata": {
        "id": "pCHapY5An22K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))"
      ],
      "metadata": {
        "id": "YbP8VBtp0M8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer= tf.compat.v1.train.AdamOptimizer(learning_rate=0.01)\n",
        "optimize=optimizer.minimize(cost)"
      ],
      "metadata": {
        "id": "Zt44lgWL3XCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sess= tf.compat.v1.Session()\n",
        "sess.run(tf.compat.v1.global_variables_initializer())"
      ],
      "metadata": {
        "id": "DQqjSRHi3uXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=100\n",
        "for i in range(25):\n",
        "  num_batches=int(mnist.train.num_examples/batch_size)\n",
        "  total_cost=0\n",
        "  for j in range(num_batches):\n",
        "    batch_x, batch_y=mnist.tzrain.next_batch(batch_size)\n",
        "    c, _ = sess.run([cost, optimize], feed_dict={x:batch_x, y:batch_y})\n",
        "    total_cost+=c\n",
        "  print(total_cost)"
      ],
      "metadata": {
        "id": "Zv1JvbOE4ByH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=tf.argmax(pred, 1)\n",
        "correct_labels=tf.argmax(y,1)\n",
        "correct_predictions=tf.equal(prediction,correct_labels)\n",
        "prediction,correct_preds= sess.run([prediction, correct_predictions], feed_dict={x:mnist.test})\n",
        "correct_preds.sum()"
      ],
      "metadata": {
        "id": "M4hZcZTv5OUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding dropout layer\n",
        "\n",
        "def cnn(x, weights, biases, keep_prob):\n",
        "  x = tf.reshape(x, shape=[-1 ,input_height,input_width, input_channels])\n",
        "  conv1 = conv(x,weights['wc1'],biases['bc1'])\n",
        "  conv1_pool= maxpooling(conv1, max_pool1_k)\n",
        "\n",
        "  conv2= conv(conv1_pool, weights['wc2'], biases['bc2'])\n",
        "  conv2_pool=maxpooling(conv2, max_pool2_k)\n",
        "\n",
        "  hidden_input= tf.reshape(conv2_pool, shape=[-1,input_size_to_hidden])\n",
        "  hidden_output_before_activation= tf.add(tf.matmul(hidden_input, weights['wh1']), biases['bh1'])\n",
        "  hidden_output_before_dropout= tf.nn.relu(hidden_output_before_activation)\n",
        "  hidden_output=tf..nn.dropout(hidden_output_before_dropout, keep_prob)\n",
        "\n",
        "  output= tf.add(tf.matmul(hidden_output, weights['wo']), biases['bo'])\n",
        "  return output\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YP2bYKt36XvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(\"float\",[None,input_pixels])\n",
        "y= tf.placeholder(tf.int32, [None, n_out])\n",
        "keep_prob=tf.placeholder(\"float\")\n",
        "pred= cnn(x, weights, biases, keep_prob)"
      ],
      "metadata": {
        "id": "XGIJJUmj_IQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=100\n",
        "for i in range(25):\n",
        "  num_batches=int(mnist.train.num_examples/batch_size)\n",
        "  total_cost=0\n",
        "  for j in range(num_batches):\n",
        "    batch_x, batch_y=mnist.tzrain.next_batch(batch_size)\n",
        "    c, _ = sess.run([cost, optimize], feed_dict={x:batch_x, y:batch_y, keep_prob=0.8})\n",
        "    total_cost+=c\n",
        "  print(total_cost)"
      ],
      "metadata": {
        "id": "Fjsvzrgd_h7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=tf.argmax(pred, 1)\n",
        "correct_labels=tf.argmax(y,1)\n",
        "correct_predictions=tf.equal(prediction,correct_labels)\n",
        "prediction,correct_preds= sess.run([prediction, correct_predictions], feed_dict={x:mnist.test, keep_prob=1})\n",
        "correct_preds.sum()"
      ],
      "metadata": {
        "id": "eT2XPHgW_pH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "92GvVnUlK1aI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN"
      ],
      "metadata": {
        "id": "hOw4zyssK3Hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "W25B5MVhK5Eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=read_csv('/content/international-airline-passengers.csv', usecols=[1])"
      ],
      "metadata": {
        "id": "uD13j-HrVnEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "5Y-L6PaRWWNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values= df.values.astype('float32')\n",
        "values.shape"
      ],
      "metadata": {
        "id": "TgtcWm19Xfbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size= int((values.shape[0] * 0.67))\n",
        "test_size=values.shape[0] - train_size\n",
        "train= values[0: train_size]\n",
        "\n",
        "test=values[train_size:]"
      ],
      "metadata": {
        "id": "VHTyC-jnXvXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler \n",
        "scaler= MinMaxScaler(feature_range=(0,1))\n",
        "train=scaler.fit_transform(train)\n",
        "test=scaler.transform(test)"
      ],
      "metadata": {
        "id": "PEbOxx89Yngj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(data, k):\n",
        "  datax, datay= [], []\n",
        "  for i in range(data.shape[0] - k):\n",
        "    x= data[i:i+k, 0]\n",
        "    y= data[i + k , 0]\n",
        "    datax.append(x)\n",
        "    datay.append(y)\n",
        "  return np.array(datax), np.array(datay)  "
      ],
      "metadata": {
        "id": "GqQFk38gZgaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "look_back=12\n",
        "trainx, trainy=create_dataset(train, look_back)\n",
        "testx, testy=create_dataset(test, look_back)"
      ],
      "metadata": {
        "id": "B2mJVYABbLrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainx=np.reshape(trainx, (trainx.shape[0], trainx.shape[1], 1))\n",
        "testx=np.reshape(testx, (testx.shape[0], testx.shape[1], 1))\n",
        "trainx.shape"
      ],
      "metadata": {
        "id": "IOSScBIsgMWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN, Dense"
      ],
      "metadata": {
        "id": "Z4efcOwrcJJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(SimpleRNN(4, input_shape=(look_back, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(trainx, trainy, epochs=10, batch_size=1)"
      ],
      "metadata": {
        "id": "otk57sEJeO2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testPredict=model.predict(testx)\n",
        "testPredict=scaler.inverse_transform(testPredict).ravel()\n",
        "\n",
        "trainPredict=model.predict(trainx)\n",
        "trainPredict=scaler.inverse_transform(trainPredict).ravel()\n",
        "\n",
        "testTrue=scaler.inverse_transform([testy]).ravel()\n",
        "trainTrue=scaler.inverse_transform([trainy]).ravel()\n",
        "\n",
        "testPredict.shape, testTrue.shape\n"
      ],
      "metadata": {
        "id": "IYQzZvV9hd_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "Trpi4eLPkSgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(trainTrue, c='g')\n",
        "plt.plot(trainPredict, c='b')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gEc1b0IZkZyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combinationPredicted= np.concatenate((trainPredict, testPredict))\n",
        "combinedTrue=np.concatenate((trainTrue, testTrue))\n",
        "plt.plot(combinedTrue, c='g')\n",
        "plt.plot(combinationPredicted, c='b')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vZrH7shTktdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VEPkyQ6ayBoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Long Short_ Term Memory(LSTM)"
      ],
      "metadata": {
        "id": "upxJ2cZ4yDA8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* k mean"
      ],
      "metadata": {
        "id": "onwXDHIVNgBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "nWMYJivFNku_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])"
      ],
      "metadata": {
        "id": "gxykjIStyPIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x[:,0], x[:,1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4R1hNjQlOREk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "lC4Lmx_GOgxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_mean=KMeans(n_clusters=2)"
      ],
      "metadata": {
        "id": "Yo7Qdy8XOs07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_mean.fit(x)"
      ],
      "metadata": {
        "id": "ZoCgqPZ9O4jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_mean.labels_"
      ],
      "metadata": {
        "id": "39mC88A_O-YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_mean.cluster_centers_"
      ],
      "metadata": {
        "id": "DeYi9a2BPZS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x[:,0], x[:,1], c=k_mean.labels_)\n",
        "plt.scatter(k_mean.cluster_centers_[:,0], k_mean.cluster_centers_[:,1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tew8vNA5PeXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* starter code for KMean"
      ],
      "metadata": {
        "id": "tvb60CTrUfap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def fit(data, k=2, max_iter=100):\n",
        "  means=[]\n",
        "  # randomly initialize the mean\n",
        "  for i in range(k):\n",
        "    means.append(data[i])\n",
        "  for i in range(max_iter):\n",
        "    # assign the data points to the cluster that they belong to \n",
        "    # create empty clusters\n",
        "    clusters=[]\n",
        "    for j in range(k):\n",
        "      clusters.append([])\n",
        "    for point in data:\n",
        "      # find distance all means values\n",
        "      distances=[((point-m)**2).sum() for m in means] \n",
        "      # find min distence\n",
        "      minDistances= min(distances)\n",
        "      #find the mean for which we got the minimum distance ---1\n",
        "      l = distances.index(minDistances)\n",
        "      # add this point cluster 1\n",
        "      clusters[l].append(point)\n",
        "      # claculate the mean values\n",
        "    change=False  \n",
        "    for j in range(k):\n",
        "      new_mean=np.average(clusters[j],axis=0)\n",
        "      if not np.array_equal(means[j], new_mean):\n",
        "        change=True\n",
        "      means[j]=new_mean\n",
        "    if not change:\n",
        "      break  \n",
        "  return means"
      ],
      "metadata": {
        "id": "x-ONkxVNUcp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(test_data, means):\n",
        "  predictions=[]\n",
        "  for point in test_data:\n",
        "    # find distance to all means values\n",
        "    distances=[((point-m)**2).sum() for m in means]\n",
        "    # find min distance \n",
        "    minDistance=min(distances)\n",
        "    # find the mean for which we got the minmum distance --1\n",
        "    l = distances.index(minDistance)\n",
        "    # add this point to cluster l\n",
        "    predictions.append(l)\n",
        "  return predictions     "
      ],
      "metadata": {
        "id": "hJiRfseTa6Hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "means=fit(x)"
      ],
      "metadata": {
        "id": "Z74O0BPaU6tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(x, means)\n"
      ],
      "metadata": {
        "id": "AwxlEbksccnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# class\n",
        "class K_Mean:\n",
        "  def __init__(self, k=2, max_iter=100):\n",
        "    print(\"constructor\")\n",
        "    self.k=k\n",
        "    self.max_iter=max_iter\n",
        "  def fit(self,data):\n",
        "    self.means=[]\n",
        "  # randomly initialize the mean\n",
        "    for i in range(self.k):\n",
        "      self.means.append(data[i])\n",
        "    for i in range(self.max_iter):\n",
        "      # assign the data points to the cluster that they belong to \n",
        "      # create empty clusters\n",
        "      clusters=[]\n",
        "      for j in range(self.k):\n",
        "        clusters.append([])\n",
        "      for point in data:\n",
        "        # find distance all means values\n",
        "        distances=[((point-m)**2).sum() for m in self.means] \n",
        "        # find min distence\n",
        "        minDistances= min(distances)\n",
        "        #find the mean for which we got the minimum distance ---1\n",
        "        l = distances.index(minDistances)\n",
        "        # add this point cluster 1\n",
        "        clusters[l].append(point)\n",
        "        # claculate the mean values\n",
        "      change=False  \n",
        "      for j in range(self.k):\n",
        "        new_mean=np.average(clusters[j],axis=0)\n",
        "        if not np.array_equal(self.means[j], new_mean):\n",
        "          change=True\n",
        "        self.means[j]=new_mean\n",
        "      if not change:\n",
        "        break  \n",
        "      \n",
        "  def predict(self,test_data):\n",
        "    predictions=[]\n",
        "    for point in test_data:\n",
        "      # find distance to all means values\n",
        "      distances=[((point-m)**2).sum() for m in self.means]\n",
        "      # find min distance \n",
        "      minDistance=min(distances)\n",
        "      # find the mean for which we got the minmum distance --1\n",
        "      l = distances.index(minDistance)\n",
        "      # add this point to cluster l\n",
        "      predictions.append(l)\n",
        "    return predictions     \n"
      ],
      "metadata": {
        "id": "OLxXl8B2gKnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmean=K_Mean(2, 10)"
      ],
      "metadata": {
        "id": "y-Ehp3Wuj5bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmean.fit(x)\n"
      ],
      "metadata": {
        "id": "Gawspj-_j_tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmean.predict(x)"
      ],
      "metadata": {
        "id": "lWR14zlR5m0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmean.means"
      ],
      "metadata": {
        "id": "DVJGFRiq5taz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}